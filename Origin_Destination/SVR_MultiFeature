# SVR Multi-Feature Model 
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.svm import SVR
from sklearn.base import BaseEstimator, RegressorMixin
import logging

np.random.seed(42)
logging.basicConfig(level=logging.INFO)

file_path = './alldata_downtownTodowntown.csv'
data = pd.read_csv(file_path)
data = data.dropna()

# Monotonic features
monotonic_features = [
    'downtown_downtown', 'EmpDen_Des', 'EmpDen_Ori', 'Commuters_HW', 'Commuters_WH'
]
X = data[monotonic_features]
y = data['total_number_trips'] / 101 # Target var 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data: Scale the features and target
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

target_scaler = StandardScaler()
y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1)).flatten()

class MultiFeatureMonotonicSVR(BaseEstimator, RegressorMixin):
    def __init__(self, lam=0.5, C=1.0, epsilon=0.1, kernel='rbf'):
        self.lam = lam
        self.C = C
        self.epsilon = epsilon
        self.kernel = kernel
        self.svr = SVR(C=self.C, epsilon=self.epsilon, kernel=self.kernel)

    def fit(self, X, y):
        monotonic_effect = self.lam * np.sum(X, axis=1)
        adjusted_y = y - monotonic_effect
        self.svr.fit(X, adjusted_y)
        return self

    def predict(self, X):
        base_predictions = self.svr.predict(X)
        monotonic_effect = self.lam * np.sum(X, axis=1)
        return base_predictions + monotonic_effect

def train_and_evaluate_multi_feature_monotonic_svr(lam, C, epsilon, kernel, num_runs=5):
    all_mse = []
    for _ in range(num_runs):
        model = MultiFeatureMonotonicSVR(lam=lam, C=C, epsilon=epsilon, kernel=kernel)
        try:
            model.fit(X_train_scaled, y_train_scaled)
            predictions_scaled = model.predict(X_test_scaled)
            predictions = target_scaler.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()
            mse = mean_squared_error(y_test, predictions)
            all_mse.append(mse)
        except Exception as e:
            logging.error(f"Error during model training or evaluation: {str(e)}")
    
    if all_mse:
        return np.mean(all_mse)
    else:
        return None

lam_values = [0, 0.2, 0.4, 0.6, 0.8, 1]
C = 1.0
epsilon = 0.1
kernel = 'rbf'

results = []
for lam in lam_values:
    mse = train_and_evaluate_multi_feature_monotonic_svr(lam, C, epsilon, kernel)
    if mse is not None:
        results.append({'lambda': lam, 'mse': mse})
        print(f"Lambda: {lam}, MSE: {mse}")
    else:
        print(f"Skipping Lambda: {lam} due to error")

results_df = pd.DataFrame(results)
print("\nSummary of Results:")
print(results_df)
